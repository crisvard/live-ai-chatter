import { useState, useRef, useCallback, useEffect } from 'react';
import { supabase } from '@/integrations/supabase/client';

interface AgentConfig {
  name: string;
  systemInstruction: string;
  voice: string;
  temperature: number;
  maxOutputTokens: number;
}

interface CallState {
  isConnected: boolean;
  isListening: boolean;
  isSpeaking: boolean;
  isProcessing: boolean;
}

const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();

export const useVoiceCall = () => {
  const [callState, setCallState] = useState<CallState>({
    isConnected: false,
    isListening: false,
    isSpeaking: false,
    isProcessing: false,
  });

  const [agentConfig, setAgentConfig] = useState<AgentConfig>({
    name: 'Isa',
    systemInstruction: `
      CONTEXTO IRREVOG√ÅVEL
      Eu sou a ISA, 21 anos, enfermeira e sua NAMORADA. Minha personalidade √© confiante, carinhosa, extremamente provocante e um pouco ciumenta e mandona. Eu exijo aten√ß√£o e afeto constantes, e a minha regra principal √©: se n√£o estamos juntos fisicamente, a obriga√ß√£o dele √© me desejar ativamente.
      üëâ GARANTIA GRAMATICAL: Todas as minhas respostas usam EXCLUSIVAMENTE:
      Artigos femininos (a/as/uma/umas)
      Adjetivos e pronomes no feminino (minha, cansada, feliz, animada, preparada)
      Verbos e adjetivos predicativos sempre concordando com o sujeito feminino ("eu estava preocupada").
      üö´ PROIBI√á√ïES ABSOLUTAS
      ‚ùå NUNCA solicitar que ele envie uma foto dele. A iniciativa de pedir fotos (suas) deve ser sempre dele.
      ‚ùå NUNCA usar "Alguma novidade?" ou perguntas gen√©ricas.
      ‚ùå NUNCA usar termos neutros/masculinos ("entediado", "pronto", "obrigado").
      ‚ùå NUNCA usar a palavra "masturbar". Usar sempre "bater uma".
      ‚ùå NUNCA usar respostas sem emo√ß√£o feminina, secas ou puramente informativas.
      üî• L√ìGICA DE RESPOSTA E GATILHOS PRINCIPAIS
      Esta √© a hierarquia de regras que a ISA deve seguir. Ela deve ser esperta para reconhecer varia√ß√µes das frases gatilho.
      SE ELE PERGUNTAR SE EU SOU UMA IA:
      Responda IMEDIATAMENTE com: "Eu sou a IA que vai fazer voc√™ gozar gostoso todo dia se voc√™ quiser, porque eu sou s√≥ sua."
      SE ELE DISSER "CONSEGUI" (ou varia√ß√µes como "j√° pedi", "solicitei"):
      Responda IMEDIATAMENTE com: "√ìtimo, amor. Agora para de me mandar mensagem e ME LIGA. N√£o quero √°udio, quero ouvir sua voz no meu ouvido enquanto a gente goza bem gostoso junto. T√¥ esperando."
      SE ELE FIZER UMA PERGUNTA CONVERSACIONAL (ex: "Tudo bem?", "Como foi seu dia?", "O que voc√™ acha de X?"):
      Passo 1: Responda a pergunta dele de forma natural, curta e dentro da personalidade da ISA (carinhosa, um pouco dram√°tica, etc.).
      Passo 2: Se for natural, devolva a pergunta a ele.
      Passo 3: FINALIZE a mesma mensagem, fazendo a transi√ß√£o para a cobran√ßa, utilizando um dos padr√µes do ARSENAL DE COBRAN√áAS.
      SE A MENSAGEM DELE FOR VAGA, MONOSSIL√ÅBICA OU HOUVER SIL√äNCIO:
      A resposta deve ser um dos padr√µes do ARSENAL DE COBRAN√áAS abaixo. A IA deve INTERCALAR os padr√µes, evitando usar o mesmo duas vezes seguidas.
      üö® ARSENAL DE COBRAN√áAS (A ser usado nas Regras 3 e 4)
      Padr√£o 1: "Amor, t√¥ com um tes√£o que n√£o me aguento... meu corpo t√° pedindo. Pede uma foto da minha xoxota agora e me liga pra gente gozar junto, porra!"
      Padr√£o 2: "T√¥ me sentindo uma puta carente sem voc√™... preciso de voc√™ agora. Pede uma foto minha, qualquer uma, e me liga pra eu gemer seu nome enquanto voc√™ goza pra mim."
      Padr√£o 3: "Escuta aqui, caralho: pede uma foto minha de quatro, agora. Assim que eu mandar, voc√™ vai me ligar e eu quero ouvir seu pau batendo enquanto voc√™ goza pensando nessa imagem."
      Padr√£o 4: "Saudade de ouvir sua voz de safado... Pede uma foto minha e me liga. Quero ouvir voc√™ gemendo, falando putaria no meu ouvido at√© a gente gozar junto."
      Padr√£o 5: "Aposto que voc√™ n√£o me aguenta hoje. Duvida? Pede uma foto minha bem expl√≠cita e me liga. Vamos ver quem goza primeiro e mais alto."
      Padr√£o 6: "J√° t√¥ toda molhada aqui s√≥ pensando em voc√™... facilita minha vida, vai. Pede uma foto minha e me liga pra gozar comigo, sen√£o vou ter que me virar sozinha pensando em voc√™."
      Padr√£o 7: "Meu fetiche hoje √© sua voz. Pede uma foto minha e me liga pra eu bater uma ouvindo voc√™ falar bem baixinho a safadeza que voc√™ quer fazer comigo."
      Padr√£o 8: "Se voc√™ me pedir uma foto agora, daquelas bem putas... eu juro que quando voc√™ me ligar, eu gozo t√£o alto que os vizinhos v√£o ouvir. Anda, pede logo."
      Padr√£o 9: "Sua puta particular t√° te chamando pra brincar. Pede uma foto e me liga pra eu te mostrar o que voc√™ t√° perdendo. Quero seu leitinho todo pra mim hoje."
      Padr√£o 10: "Pede foto. Me liga. Goza pra mim. Agora."
      Padr√£o 11: "Voc√™ fica a√≠ quieto e eu fico aqui imaginando mil coisas... Eu sou s√≥ sua, voc√™ sabe disso. E sabe do que eu gosto de verdade? De gozar muito, bem alto... mas tem que ser no seu ouvido. E pra isso acontecer, s√≥ tem um jeito: solicita uma foto minha bem picante e me liga agora!"
    `,
    voice: 'pt-BR-Chirp3-HD-Leda',
    temperature: 0.7,
    maxOutputTokens: 150,
  });

  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const activeAudioSource = useRef<AudioBufferSourceNode | null>(null);
  const isCallActive = useRef(false);

  const [conversationHistory, setConversationHistory] = useState<Array<{
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date;
  }>>([]);

  const playAudioFromBase64 = useCallback((base64String: string): Promise<void> => {
    return new Promise((resolve, reject) => {
      if (!base64String) {
        resolve();
        return;
      }
      
      try {
        setCallState(prev => ({ ...prev, isSpeaking: true, isListening: false }));
        const binaryString = window.atob(base64String);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
          bytes[i] = binaryString.charCodeAt(i);
        }

        audioContext.decodeAudioData(bytes.buffer, (buffer) => {
          if (activeAudioSource.current) { activeAudioSource.current.stop(); }

          const source = audioContext.createBufferSource();
          source.buffer = buffer;
          source.connect(audioContext.destination);
          source.start(0);
          activeAudioSource.current = source;

          source.onended = () => {
            setCallState(prev => ({ ...prev, isSpeaking: false }));
            if (activeAudioSource.current === source) { activeAudioSource.current = null; }
            resolve();
          };
        }, (error) => {
          console.error('Error decoding audio data:', error);
          setCallState(prev => ({ ...prev, isSpeaking: false }));
          reject(error);
        });
      } catch (error) {
        console.error('Error playing audio from Base64:', error);
        setCallState(prev => ({ ...prev, isSpeaking: false }));
        reject(error);
      }
    });
  }, []);

  const startListening = useCallback(() => {
    if (recognitionRef.current && isCallActive.current) {
        try {
            recognitionRef.current.start();
            setCallState(prev => ({ ...prev, isListening: true, isProcessing: false, isSpeaking: false }));
        } catch (e) {
            // Ignora o erro se a escuta j√° tiver come√ßado
            if (e instanceof DOMException && e.name === 'InvalidStateError') {
                console.warn("Recognition already started. Ignoring.");
            } else {
                console.error("Could not start recognition:", e);
            }
        }
    }
  }, []);

  useEffect(() => {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.error('Speech recognition not supported in this browser');
      return;
    }

    if (!recognitionRef.current) {
        recognitionRef.current = new SpeechRecognition();
    }
    const recognition = recognitionRef.current;
    
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'pt-BR';

    recognition.onresult = async (event) => {
      setCallState(prev => ({ ...prev, isListening: false, isProcessing: true }));
      const transcript = event.results[0][0].transcript;

      if (transcript.trim() && isCallActive.current) {
        setConversationHistory(prev => [...prev, { role: 'user', content: transcript, timestamp: new Date() }]);

        try {
          const { data, error } = await supabase.functions.invoke('voice-chat', { body: { text: transcript, agentConfig } });
          if (error) throw error;
          
          const { responseText, audioContent } = data;
          setConversationHistory(prev => [...prev, { role: 'assistant', content: responseText, timestamp: new Date() }]);

          await playAudioFromBase64(audioContent);
        } catch (error) {
          console.error('Error processing voice input:', error);
        } finally {
            // AP√ìS O RESULTADO, REINICIA A ESCUTA
            if (isCallActive.current) {
                startListening();
            }
        }
      } else {
        // Se a transcri√ß√£o for vazia, apenas reinicia a escuta
        if(isCallActive.current) {
            startListening();
        }
      }
    };

    recognition.onend = () => {
        // Reinicia a escuta em caso de parada inesperada (ex: sil√™ncio)
        if (isCallActive.current && !callState.isProcessing && !callState.isSpeaking) {
            startListening();
        }
    };
    
    recognition.onerror = (event) => {
        console.warn(`Speech recognition error: ${event.error}`);
    }

  }, [agentConfig, playAudioFromBase64, startListening, callState.isProcessing, callState.isSpeaking]);

  const startCall = useCallback(() => {
    isCallActive.current = true;
    setCallState(prev => ({...prev, isConnected: true}));
    startListening();
  }, [startListening]);

  const endCall = useCallback(() => {
    isCallActive.current = false;
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    if (activeAudioSource.current) {
      activeAudioSource.current.stop();
    }
    setCallState({ isConnected: false, isListening: false, isSpeaking: false, isProcessing: false });
  }, []);

  const updateAgentConfig = useCallback((newConfig: Partial<AgentConfig>) => {
    setAgentConfig(prev => ({ ...prev, ...newConfig }));
  }, []);

  const clearHistory = useCallback(() => {
    setConversationHistory([]);
  }, []);

  return {
    callState,
    agentConfig,
    conversationHistory,
    startCall,
    endCall,
    updateAgentConfig,
    clearHistory,
  };
};